{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing Event Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Purpose\n",
    "Since in Apache Cassandra we model tables based on the queries, we often load subsets of the same data into different tables.  Therefore, if we have a set of data files (daily event files in this case), it is more efficient to first combine them into a single file, and then read this single file once and load its contents into data tables.  Additionally, since the event/log files might have data points which are not necessary for us to capture in the data tables, we can also eliminate them as we create this new/combined data file.  Considering the expected size of these (potentially streaming data) event logs, these design efficiencies should go a long way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create a list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Process event data files and merge them into a single file that will be used for Apache Cassandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initiate an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# read a csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # create a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "         # extract each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# Create a smaller event data csv file called event_datafile_new csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Expected Result\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> <br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Apache Cassandra Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Problem\n",
    "\n",
    "Business team has provided us with the queries our Apache Cassandra data model needs to be able to answer by using the event data.  In order to satisfy the business request, we need to evaluate the queries and identify what table(s) we need to create, data points within each table, as well as PRIMARY/PARTITION keys/CLUSTERING column(s), to ensure the questions can be answered correctly and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Design\n",
    "\n",
    "Let's begin by evaluating each query to identify needed table structures and primary/partition keys/clustering column(s)\n",
    "\n",
    "**Query 1:** Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "To satisfy this query, our \"song_playlist_session_item\" table should have the following columns (with data types matching those in the data file):\n",
    "- sessionId\n",
    "- itemInSession\n",
    "- artist\n",
    "- song\n",
    "- length\n",
    "\n",
    "SessionID + itemInSession should be our composite PRIMARY KEY (to uniquely identify rows) as well as a PARTITION KEY (to allow for efficient lookups for this query).\n",
    "\n",
    "**Query 2:** Give me the name of the artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "To satisfy this query, our \"song_playlist_session\" table should have the following columns (with data types matching those in the data file):\n",
    "- userId\n",
    "- sessionId\n",
    "- itemInSession\n",
    "- artist\n",
    "- song\n",
    "- firstName\n",
    "- lastName\n",
    "\n",
    "userId + sessionId + itemInSession should be our composite PRIMARY KEY (to uniquely identify rows), userId + sessionId should be our PARTITION KEY (to allow for efficient lookups for this query) and itemInSession should be our CLUSTERING COLUMN (as the query requests we sort data by itemInSession).\n",
    "\n",
    "**Query 3:** Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "To satisfy this query, our \"song_user\" table should have the following columns (with data types matching those in the data file):\n",
    "- song\n",
    "- userId\n",
    "- firstName\n",
    "- lastName\n",
    "\n",
    "song + userId should be our composite PRIMARY KEY (to uniquely identify rows), where song is a PARTITION KEY (to allow for efficient lookups for this query) and userId is our CLUSTERING COLUMN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Solution\n",
    "\n",
    "We will follow these steps for solution implementation and testing\n",
    "\n",
    "1. Create Apache Cassandra cluster\n",
    "2. Create a keyspace and connect to it\n",
    "3. Create 3 tables\n",
    "4. Load data into 3 tables\n",
    "5. Run 3 queries to ensure we are getting expected results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Apache Cassandra cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try: \n",
    "    # Define a cluster\n",
    "    cluster = Cluster(['127.0.0.1']) #If you have a locally installed Apache Cassandra instance\n",
    "    \n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create table for query 1\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_playlist_session_item (\n",
    "        sessionId      INT, \n",
    "        itemInSession  INT, \n",
    "        artist         TEXT, \n",
    "        song           TEXT, \n",
    "        length         TEXT, \n",
    "        PRIMARY KEY((sessionId, itemInSession))\n",
    "        );\n",
    "\"\"\")\n",
    "except Exception as e:\n",
    "    print(e) \n",
    "    \n",
    "# Create table for query 2\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_playlist_session (\n",
    "        userId         INT,\n",
    "        sessionId      INT, \n",
    "        itemInSession  INT, \n",
    "        artist         TEXT, \n",
    "        song           TEXT, \n",
    "        firstName      TEXT, \n",
    "        lastName       TEXT,\n",
    "        PRIMARY KEY((userId, sessionId), itemInSession)\n",
    "        );\n",
    "\"\"\")\n",
    "except Exception as e:\n",
    "    print(e) \n",
    "    \n",
    "# Create table for query 3\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_user (\n",
    "        song           TEXT, \n",
    "        userId         INT,\n",
    "        firstName      TEXT, \n",
    "        lastName       TEXT,\n",
    "        PRIMARY KEY(song, userId)\n",
    "        );\n",
    "\"\"\")\n",
    "except Exception as e:\n",
    "    print(e) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We will open a file once, read it once, and load data into 3 tables at the same time\n",
    "\n",
    "# Define filename of the data file to read\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "# Define insert queries\n",
    "# Query 1\n",
    "query1 = \"INSERT INTO song_playlist_session_item (sessionId, itemInSession, artist, song, length)\"\n",
    "query1 = query1 + \" VALUES (%s, %s, %s, %s, %s)\"  \n",
    "\n",
    "# Query 2\n",
    "query2 = \"INSERT INTO song_playlist_session (userId, sessionid, itemInSession, artist, song, firstName, lastName)\"\n",
    "query2 = query2 + \" VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "\n",
    "# Query 3\n",
    "query3 = \"INSERT INTO song_user (song, userId, firstName, lastName)\"\n",
    "query3 = query3 + \" VALUES (%s,%s,%s,%s)\"\n",
    "\n",
    "# Open the file, read it row by row, extract needed data points, and insert them into the tables\n",
    "# Loading into 3 tables at the same time allows us to read the data file only once!\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:   \n",
    "        # execute insert query 1\n",
    "        try:\n",
    "            session.execute(query1, (int(line[8]), int(line[3]), line[0], line[9], line[5]))\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "        # execute insert query 2\n",
    "        try:\n",
    "            session.execute(query2, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "        except Exception as e:\n",
    "            print(e)   \n",
    "        # execute insert query 3\n",
    "        try:\n",
    "            session.execute(query3, (line[9], int(line[10]), line[1], line[4]))\n",
    "        except Exception as e:\n",
    "            print(e)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Test Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "# Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "# sessionId = 338, and itemInSession = 4   \n",
    "query = \"SELECT artist, song, length FROM song_playlist_session_item WHERE sessionId = 338 and itemInSession = 4\"\n",
    "\n",
    "## Execute query\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Output query results\n",
    "for row in rows:\n",
    "    print (row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# Give me the name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "query = \"SELECT artist, song, firstname, lastname  FROM song_playlist_session WHERE userId = 10 AND sessionId = 182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Output query results\n",
    "for row in rows:\n",
    "    print (row.artist, row.song, row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query = \"SELECT firstname, lastname  FROM song_user WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "# Execute the query\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Output query results\n",
    "for row in rows:\n",
    "    print (row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop the tables created before closing out the sessions\n",
    "query = \"DROP TABLE IF EXISTS song_playlist_session_item\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS song_playlist_session\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "query = \"DROP TABLE IF EXISTS song_user\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
